{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bf47f6-8bda-4d52-9180-9ddcbd44ccc2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# **2. Predictive Text, Part I: N-Grams**\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/autocomplete.png\" width=\"500\" style=\" display: block; margin-left: auto; margin-right: auto;\"/>\n",
    "</div>\n",
    "\n",
    "In this section, we will build **predictive text**, a system that suggests the next word while a user is typing. Predictive text is used in mobile phone keyboards, search applications, AI-powered email composition, and more.\n",
    "\n",
    "The primary goal of a predictive text system is *given some sequence of words, predict the most likely next word*.\n",
    "\n",
    "#### How do we do it?\n",
    "In Natural Language Processing (NLP), this can be solved with a **language model**. A language model learns the distribution of words in text. We will build a simple language model that learns common strings of two or three words.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f4658-fc08-4102-9060-29bca34ce78d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## **Data Preparation**\n",
    "### Load the corpus\n",
    "For this application, we are using English text from the COCA corpus. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Like before, feel free to use your own language instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a229d2-5414-4547-bcfd-32f23c822fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data\n",
    "import util\n",
    "\n",
    "# REPLACE WITH YOUR CORPUS DIRECTORY\n",
    "corpus = util.load_raw_text(corpus_directory=\"../corpora/eng\")\n",
    "corpus[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09635b7-7801-497b-8bdd-5e8929a26c21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Preprocessing and Tokenization\n",
    "Like the spellchecker, the next step is to tokenize the text into individual words. The only difference here is that we keep punctuation.\n",
    "\n",
    "#### **Exercise 1**\n",
    "Use the provided regex to tokenize the text, and return the result.\n",
    "\n",
    "<details>\n",
    "  <summary>Show answer</summary>\n",
    "      <pre style=\"background-color: honeydew; padding: 10px; border-radius: 5px;\"><code style=\"background: none;\">return re.findall(word_or_punctuation_regex, text)</code></pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5d13b-434c-4a64-b53c-2ce55435306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "word_or_punctuation_regex = r\"[\\w|\\']+|[\\.|\\,|\\?|\\!]\"\n",
    "\n",
    "def preprocess(text):\n",
    "    text = util.strip_accents(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # TODO: Use the provided regex to tokenize the text, and return the result\n",
    "\n",
    "tokens_filtered = preprocess(corpus)\n",
    "\n",
    "print(len(tokens_filtered), \"total tokens\")\n",
    "print(tokens_filtered[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6801ad-251b-466f-9ea2-e50fa58b22b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## **N-Gram Modeling**\n",
    "Now, let's build our first model. For this we will use *n-grams*.\n",
    "\n",
    "An n-gram is simply a sequence of *n* words that occurs in our text. For instance, consider the sentence:\n",
    "\n",
    "> What is your name?\n",
    "\n",
    "If we got the list of all of the *bigrams* (2 words each) in the sentence, we would have:\n",
    "\n",
    "- *What is*\n",
    "- *is your*\n",
    "- *your name*\n",
    "- *name ?*\n",
    "\n",
    "If we got the list of all of the *trigrams* (3 words each) we would get:\n",
    "\n",
    "- *What is your*\n",
    "- *is your name*\n",
    "- *your name ?*\n",
    "\n",
    "And so on, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49609b51-0373-45d2-bf28-d25a4ad8cb79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Using N-grams as a language model\n",
    "\n",
    "We can easily use the idea of n-grams to build a simple language model. For instance, if we are trying to predict the next word, using trigrams, given the input:\n",
    "\n",
    "> What is your ...\n",
    "\n",
    "We can look at all of the trigrams that start with *is your*, and choose the most common one. Let's use our tokenized text to get a list of all of the n-grams that occur in the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3d04e-2ff1-45ac-9e76-8d97f69243ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Padding sentences\n",
    "Right now, we would have n-grams that cross sentence boundaries, such as \"headlines . you\". This isn't super useful, so a common technique is to **pad** each sentence with tokens representing the start of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ecaa5-650e-4a11-8e1a-eafca5a9681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(text: list, num_padding: int):\n",
    "    \n",
    "    padded_text = []\n",
    "    \n",
    "    # Add initial padding to the first sentence\n",
    "    for _ in range(num_padding):\n",
    "        padded_text.append(\"<s>\")\n",
    "    \n",
    "    for word in text:\n",
    "        padded_text.append(word)\n",
    "\n",
    "        # Every time we see an end punctuation mark, add <s> tokens after it\n",
    "        # REPLACE IF YOUR LANGUAGE USES DIFFERENT END PUNCTUATION\n",
    "        if word in [\".\", \"?\", \"!\"]:\n",
    "            for _ in range(num_padding):\n",
    "                padded_text.append(\"<s>\")\n",
    "        \n",
    "        \n",
    "    return padded_text\n",
    "\n",
    "print(pad(tokens_filtered, 2)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6e534-f8de-4b0d-bd82-f0637a8bf8c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Create a list of n-grams\n",
    "The following code uses the **NLTK** library to create a list of trigrams.\n",
    "\n",
    "#### **Exercise 2**\n",
    "What would we change to use bigrams instead?\n",
    "\n",
    "<details>\n",
    "  <summary>Show answer</summary>\n",
    "      <pre style=\"background-color: honeydew; padding: 10px; border-radius: 5px;\"><code style=\"background: none;\">padded_tokens = pad(tokens_filtered, 1)\n",
    "trigrams = list(ngrams(sequence=padded_tokens, n=2))</code></pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a031ba-3575-4080-917b-f38471fcb545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# Now, we can actually create the list of n-grams using the NLTK library\n",
    "padded_tokens = pad(tokens_filtered, 2)\n",
    "trigrams = list(ngrams(sequence=padded_tokens, n=3))\n",
    "trigrams[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7450ed6-be5d-4565-a30a-e0d4703ec185",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Now that we have a list of trigrams, we can count up the frequency of each different trigram.\n",
    "\n",
    "#### **Exercise 3**\n",
    "Using the list of trigrams, fill the dictionary `all_trigrams` such that the each key is a unique trigram and the value is how many times that trigram occurs in the text.\n",
    "\n",
    "<details>\n",
    "  <summary>Show answer</summary>\n",
    "      <pre style=\"background-color: honeydew; padding: 10px; border-radius: 5px;\"><code style=\"background: none;\">for gram in trigrams:\n",
    "    if gram in all_trigrams:\n",
    "        all_trigrams[gram] += 1\n",
    "    else:\n",
    "        all_trigrams[gram] = 1</code></pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbdd25-9dca-42d1-ba39-60e24d8fad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dict of all trigrams and their frequency\n",
    "all_trigrams = dict()\n",
    "\n",
    "# TODO: Add each unique trigram to the dictionary and set the value to how many times that trigram occurs in the text\n",
    "        \n",
    "len(all_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801c8a4-668d-4800-9b64-8094525e5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the twenty most common trigrams are\n",
    "sorted(all_trigrams.items(), key=lambda x: x[1], reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c76b65-79df-4c99-b5b9-6ce38cdc1ab4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Making predictions using n-grams\n",
    "\n",
    "Now that we have a count of all trigrams, we can make predictions by looking for the most common trigram that matches our input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9146a-9fca-4dee-b59d-fb288397a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_trigram_model(text, number_results = 3):\n",
    "    input_tokens = pad(preprocess(text), 2)\n",
    "    \n",
    "    # Find the last 2 tokens in the input\n",
    "    last_two_tokens = input_tokens[-2:]\n",
    "    \n",
    "    # Search our list of all trigrams to find matching trigrams\n",
    "    matching_trigrams = []\n",
    "    for item in all_trigrams.items():\n",
    "        gram = item[0]\n",
    "        \n",
    "        # Check if the first and second item in the trigram are a match\n",
    "        if gram[0] == last_two_tokens[0] and gram[1] == last_two_tokens[1]:\n",
    "            matching_trigrams.append(item)\n",
    "    \n",
    "    # Now, sort the matching trigrams by popularity and return the first `number_results` results\n",
    "    sorted_matching_trigrams = sorted(matching_trigrams, key=lambda x: x[1], reverse=True)\n",
    "    top_matching_trigrams = sorted_matching_trigrams[:number_results]\n",
    "    \n",
    "    # Last, let's just get the predicted word (the last word of the trigram)\n",
    "    predictions = [trigram[0][2] for trigram in top_matching_trigrams]\n",
    "    return predictions\n",
    "\n",
    "predict_trigram_model(\"how is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09269f56-5273-47dc-9c1d-80b89e01bf46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Make the predictive text a standalone app\n",
    "\n",
    "#### **Exercise 4**\n",
    "Create a UI using the `predict_trigram_model` function. Refer to the spellchecker for help.\n",
    "\n",
    "<details>\n",
    "  <summary>Show answer</summary>\n",
    "      <pre style=\"background-color: honeydew; padding: 10px; border-radius: 5px;\"><code style=\"background: none;\">autocompleter = gr.Interface(fn=predict_trigram_model, inputs=\"text\", outputs=\"text\", live=True)\n",
    "</code></pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64018012-2f79-42bc-9fda-dd4c12332b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "autocompleter = None\n",
    "\n",
    "# TODO: Create a UI using Gradio for predictive text\n",
    "\n",
    "autocompleter.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb2d2e-42dd-4933-86d0-3915715064bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# **Improving N-Grams with Backoff**\n",
    "Our app has one significant issue. If the phrase we enter ends with two words that don't match *any* trigram, then our model has no predictions to make.\n",
    "\n",
    "One common solution for this is to use a process called **backoff**. With backoff, if our trigram model doesn't find any results, we try to find matching *bigrams* instead. If that fails, we go to *unigrams* (which means we just use the most frequent words). This means that we always get a result, even if it isn't quite as good.\n",
    "\n",
    "Below is a model that uses backoff and an arbitrary size n-gram to make predictions, putting together everything so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc969a71-88c0-480e-9e3c-c3cc5d6643f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_models = dict()\n",
    "\n",
    "def create_ngram_model(n = 3):\n",
    "    padded_tokens = pad(tokens_filtered, n - 1)\n",
    "    grams = list(ngrams(sequence=padded_tokens, n=n))\n",
    "    \n",
    "    all_ngrams = dict()\n",
    "    for gram in grams:\n",
    "        if gram in all_ngrams:\n",
    "            all_ngrams[gram] += 1\n",
    "        else:\n",
    "            all_ngrams[gram] = 1\n",
    "    return all_ngrams\n",
    "\n",
    "\n",
    "def predict_ngram_model(text, n = 3, number_results = 3):\n",
    "    input_tokens = pad(preprocess(text), n - 1)\n",
    "    \n",
    "    while n > 0:\n",
    "        # Find the last n - 1 tokens in the input\n",
    "        last_tokens = tuple(input_tokens[-(n-1):])\n",
    "    \n",
    "        if not n in n_gram_models:\n",
    "            n_gram_models[n] = create_ngram_model(n)\n",
    "        \n",
    "        matching_ngrams = []\n",
    "        \n",
    "        for item in n_gram_models[n].items():\n",
    "            gram = item[0]\n",
    "            if gram[:-1] == last_tokens:\n",
    "                matching_ngrams.append(item)\n",
    "    \n",
    "        # Now, sort the matching n-grams by popularity and return the first `number_results` results\n",
    "        sorted_matching_ngrams = sorted(matching_ngrams, key=lambda x: x[1], reverse=True)\n",
    "        top_matching_ngrams = sorted_matching_ngrams[:number_results]\n",
    "        \n",
    "        # BACKOFF: If there are no results, drop n and try again\n",
    "        if len(top_matching_ngrams) == 0:\n",
    "            print(\"backing off to:\", n-1)\n",
    "            n = n - 1\n",
    "            continue\n",
    "    \n",
    "        # Last, let's just get the predicted word (the last word of the trigram)\n",
    "        predictions = [gram[0][-1] for gram in top_matching_ngrams]\n",
    "        return predictions\n",
    "    return []\n",
    "\n",
    "predict_ngram_model(\"why is\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666de95f-3710-4f00-ac5d-cc2d25bbfddf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## **Summary**\n",
    "In this tutorial, we built a predictive tool for a low-resource language. This included:\n",
    "- Creating a list of n-grams from the corpus\n",
    "- Using n-grams to predict the next word in a string\n",
    "- Using backoff to utilize different size n-grams as needed\n",
    "\n",
    "### **Challenges**\n",
    "1. Use the prediction function repeatedly to predict multiple sequential words given some string. For example, the string \"Why is\" might be followed by \"he doing\" or \"she doing\".\n",
    "1. Improve the predictive text app with buttons that let you add a suggestion to the text you are typing.\n",
    "1. It's a little boring to always show the top predictions. Add an element of randomness using the Python `random` library, so that the prediction function doesn't show the same results every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa2b62-4378-40af-96ef-1519d5bf28a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
