{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026241db-a85c-4189-bf1e-20f76f3f3764",
   "metadata": {},
   "source": [
    "# 2. Simple Spellchecker\n",
    "\n",
    "One simple application we can use our corpus for is creating a basic spellchecker, like you might use in Microsoft Word.\n",
    "\n",
    "There are two approaches to creating a spellchecker system. \n",
    "1. Store a huge list of words in the language, and check that every typed word is also a word in that list.\n",
    "2. Store just roots, and use morphological information to determine if a typed word is a valid form of the root.\n",
    "\n",
    "While approach 2 certainly seems more ideal, it will take a lot more work to implement effectively. We will use approach 1 for now, which is how standard tools such as Microsoft's spellchecker work.\n",
    "\n",
    "First, we'd like to compile a list of all the words we have in our corpus. To do this, we'll need to process the corpus further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88373e3e-3551-442a-81e3-89c42d22a80d",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antonses chib'aanik tanb'ij iin.\n",
      "Jinon li... tijb'ij taq qaqaaj,\n",
      "qachuuch.\n",
      "Pwes ti... toos qaqaaj,\n",
      "qachuuch.\n",
      "Tinb'ij iin qaqaaj,\n",
      "qachuuch,\n",
      "tinb'ij iin li qamaam ójor taq tziij.\n",
      "Tijb'ij taq qamaam qet',\n",
      "ójor,\n",
      "ójor taq tziij li.\n",
      "Ójor,\n",
      "cha' kongan chee',\n",
      "kongan sii'.\n",
      "Ri' li tijb'ij taq,\n",
      "kongan sii',\n",
      "kongana chee' naqaaj.\n",
      "Nimaq taq chee',\n",
      "entons ri' li tijb'ij taq.\n",
      "Toos kwand wi' chee',\n",
      "cha'.\n",
      "Tpeti jaab',\n",
      "cha',\n",
      "kwando wi' ta't.\n",
      "Pores tijb'ij taq li ójor taq tziij.\n",
      "Kwand ooj,\n",
      "xojk'iyk ojb'enaa li sii'.\n",
      "Atb'i'tqa' li sii'.\n",
      "Jataq li sii',\n",
      "per makataq maq ra chee'.\n",
      "Porke maq ra chee' nimi' jq'iij.\n",
      "I nosol ma'an taq re maq tra chee'.\n",
      "Makach' taq jwich taq ra chee'.\n",
      "Ri' li atyuter taq lajasok,\n",
      "ta' t'el awanm atkamk,\n",
      "cha' taq.\n",
      "Toons ri' li,\n",
      "toos ri' limaq taq chee'.\n",
      "Toos maa b'ensaj k'ex re chee'.\n",
      "Porke chee' re nimi' jq'iij,\n",
      "nimi' jpetiik,\n",
      "cha' taq.\n",
      "Chee' marechtqe,\n",
      "marechtqe ju...n,\n",
      "marechtqe kib',\n",
      "uxub' q'iij jwich.\n",
      "Noke nimi' jq'iij,\n",
      "cha' taq.\n",
      "Ri rere tijya's,\n",
      "tijya' teew,\n",
      "cha' taq.\n",
      "Tijya' te\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# First, let's combine all of our corpus entries into a single, huge string.\n",
    "# We will save one corpus entry, 68, for testing\n",
    "corpus_directory = \"corpus-usp\"\n",
    "\n",
    "corpus = \"\"\n",
    "\n",
    "for file_name in os.listdir(corpus_directory):\n",
    "    # Skip this file\n",
    "    if file_name == \"68.txt\" or \".txt\" not in file_name:\n",
    "        continue\n",
    "        \n",
    "    # Read the file as a string\n",
    "    file_path = os.path.join(corpus_directory, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_contents = file.read()\n",
    "        corpus += (file_contents + \"\\n\")\n",
    "        \n",
    "print(corpus[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80b9a7b-b9c5-4c9f-b2f6-dc0db4a7000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255361"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many characters are in our corpus?\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2503ef9-3038-4c67-b713-2de6032d5f38",
   "metadata": {},
   "source": [
    "Accent marks are used to indicate tone in the transcriptions. However, a speaker might not write them, so we will strip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8f4edb-3350-423f-bd22-7569e94ff2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ojor taq tziij kita' jaa,\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def strip_accents(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "strip_accents(\"ójor taq tziij kita' jaa,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256f749c-da79-4a94-9088-5d797aca7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = strip_accents(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4556503f-72df-49c2-ac3a-6e1621944b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also make everything lowercase\n",
    "corpus = corpus.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dd7d96-a256-4b7a-98d4-32cae7a7e353",
   "metadata": {},
   "source": [
    "## Create a word list\n",
    "Now, let's create a list of every word that occurs in our corpus, using word tokenization. We will ignore punctuation marks and assume that a word is surrounded by spaces or punctuation. Additionally, we'll keep a count of the frequency of each word for use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7fc4657-827d-412d-90a9-c637797a6e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " '?',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '¡',\n",
       " '¿',\n",
       " 'ß',\n",
       " '≈'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what characters appear in our corpus\n",
    "set(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c7386d-a990-4494-9172-0a3e1aa60e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antonses',\n",
       " \"chib'aanik\",\n",
       " \"tanb'ij\",\n",
       " 'iin',\n",
       " 'jinon',\n",
       " 'li',\n",
       " \"tijb'ij\",\n",
       " 'taq',\n",
       " 'qaqaaj',\n",
       " 'qachuuch',\n",
       " 'pwes',\n",
       " 'ti',\n",
       " 'toos',\n",
       " 'qaqaaj',\n",
       " 'qachuuch']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Find just words\n",
    "word_regex = r\"[\\w|\\']+\"\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(word_regex, text)\n",
    "\n",
    "words = tokenize(corpus)\n",
    "words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86257940-26f6-43bd-bcf3-7d028b4ecc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'lexicon' (dict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6771"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's get a set of words and their frequencies\n",
    "lexicon = dict()\n",
    "for word in words:\n",
    "    if word in lexicon:\n",
    "        lexicon[word] += 1\n",
    "    else:\n",
    "        lexicon[word] = 1\n",
    "\n",
    "%store lexicon\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7984ef5-c1c1-482a-a7dd-7d90a69f49a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taq', 1337),\n",
       " ('re', 1267),\n",
       " ('li', 1203),\n",
       " (\"cha'\", 1010),\n",
       " ('i', 988),\n",
       " ('man', 809),\n",
       " (\"ta'\", 782),\n",
       " ('jun', 740),\n",
       " (\"wi'\", 581),\n",
       " ('ra', 575),\n",
       " ('ri', 419),\n",
       " (\"ri'\", 386),\n",
       " ('anm', 361),\n",
       " ('chaq', 360),\n",
       " ('chi', 350),\n",
       " ('ke', 328),\n",
       " ('ya', 322),\n",
       " ('chik', 316),\n",
       " ('iin', 283),\n",
       " ('qe', 265)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what the twenty most common words are\n",
    "sorted(lexicon.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc0639-73ed-4bde-9ff6-16c7b875e69e",
   "metadata": {},
   "source": [
    "## Building a spellchecker\n",
    "Now we're ready to build our spellchecker program. To do this, we will parse and tokenize the user's input, and then we will check each word against our lexicon. If a word doesn't appear in the lexicon, we will return it in the list of mispelled words, as well as the position where it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee73016-29bc-452c-a26a-de18713fff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mispelled:\n",
      "tzijj at 30\n"
     ]
    }
   ],
   "source": [
    "def spellcheck(s):\n",
    "    # Preprocess the input\n",
    "    s = strip_accents(s)\n",
    "    s = s.lower()\n",
    "    input_words = set(tokenize(s))\n",
    "    \n",
    "    mispelled = []\n",
    "        \n",
    "    for word in input_words:\n",
    "        if not word in lexicon.keys():\n",
    "            # A spelling error!\n",
    "            # Find the indices of the word in the original text\n",
    "            word_regex = f\"(^|\\W)({word})($|\\W)\"\n",
    "            for match in re.finditer(word_regex, s):\n",
    "                mispelled.append((word, match.start(2)))\n",
    "            \n",
    "    return sorted(mispelled, key = lambda x: x[1])\n",
    "\n",
    "print(\"Mispelled:\")\n",
    "for mispelled_word, location in spellcheck(\"Kwand xink'uli'k', re ójr taq tzijj in ák'el na.\"):\n",
    "    print(f\"{mispelled_word} at {location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79955b23-48a1-43dd-8f1a-3139aa0f65b4",
   "metadata": {},
   "source": [
    "At this point, we are detecting spelling errors and reporting them appropriately. But this isn't a great tool for a user to use, so let's make it nicer to input text and see output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25a105dd-1264-4930-81bd-c7a208abd313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /Users/milesper/miniforge3/lib/python3.10/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting gradio\n",
      "  Downloading gradio-3.15.0-py3-none-any.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (1.5.0)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson\n",
      "  Downloading orjson-3.8.3-cp310-cp310-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (493 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.6/493.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting altair>=4.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (2022.10.0)\n",
      "Requirement already satisfied: requests in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (2.28.1)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Collecting markdown-it-py[linkify,plugins]\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websockets>=10.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (10.3)\n",
      "Requirement already satisfied: aiohttp in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: numpy in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (1.23.2)\n",
      "Requirement already satisfied: matplotlib in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (3.6.0)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycryptodome\n",
      "  Downloading pycryptodome-3.16.0.tar.gz (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pydantic in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (1.9.2)\n",
      "Requirement already satisfied: pyyaml in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: markupsafe in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Collecting python-multipart\n",
      "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pillow in /Users/milesper/miniforge3/lib/python3.10/site-packages (from gradio) (9.2.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (4.16.0)\n",
      "Requirement already satisfied: toolz in /Users/milesper/miniforge3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: entrypoints in /Users/milesper/miniforge3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from pandas->gradio) (2022.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from aiohttp->gradio) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from aiohttp->gradio) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Collecting starlette==0.22.0\n",
      "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from starlette==0.22.0->fastapi->gradio) (3.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from pydantic->gradio) (4.4.0)\n",
      "Requirement already satisfied: sniffio in /Users/milesper/miniforge3/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /Users/milesper/miniforge3/lib/python3.10/site-packages (from httpx->gradio) (2022.6.15)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py~=1.0\n",
      "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
      "Collecting mdit-py-plugins\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fonttools>=4.22.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from matplotlib->gradio) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from matplotlib->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from matplotlib->gradio) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from python-multipart->gradio) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from requests->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from requests->gradio) (1.26.11)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/milesper/miniforge3/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.1)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Building wheels for collected packages: ffmpy, pycryptodome, python-multipart\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=148fa849a2ae046661a40ddd80ac70f7e92cb14608c74db57799ae030ba2571a\n",
      "  Stored in directory: /Users/milesper/Library/Caches/pip/wheels/fe/17/e9/577da024bc5aede641c69f0675254c1e518db79800abbe135c\n",
      "  Building wheel for pycryptodome (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycryptodome: filename=pycryptodome-3.16.0-cp35-abi3-macosx_11_0_arm64.whl size=1531659 sha256=58b788ad7f88bcd5cf42d9f3f284432435ff8c8ff13be191976d7e23bca36c28\n",
      "  Stored in directory: /Users/milesper/Library/Caches/pip/wheels/7a/8a/76/6e5de52adfb0dee5462d54b54a610e9b5215c056d6876ce3ce\n",
      "  Building wheel for python-multipart (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31670 sha256=13f28b27f05127702a972c4a2c3cab7fb229c2e7fc298d95fdd8d81a05aedc37\n",
      "  Stored in directory: /Users/milesper/Library/Caches/pip/wheels/1a/70/03/c981b93a16009e0e54f9f16e19fd8e94c5415b805f61fd2a07\n",
      "Successfully built ffmpy pycryptodome python-multipart\n",
      "Installing collected packages: rfc3986, pydub, ffmpy, uc-micro-py, python-multipart, pycryptodome, orjson, mdurl, h11, uvicorn, starlette, markdown-it-py, linkify-it-py, httpcore, mdit-py-plugins, httpx, fastapi, altair, gradio\n",
      "  Attempting uninstall: rfc3986\n",
      "    Found existing installation: rfc3986 2.0.0\n",
      "    Uninstalling rfc3986-2.0.0:\n",
      "      Successfully uninstalled rfc3986-2.0.0\n",
      "Successfully installed altair-4.2.0 fastapi-0.88.0 ffmpy-0.3.0 gradio-3.15.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.1 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.3 pycryptodome-3.16.0 pydub-0.25.1 python-multipart-0.0.5 rfc3986-1.5.0 starlette-0.22.0 uc-micro-py-1.0.1 uvicorn-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install termcolor\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7717609-460d-446f-9f53-9dcd84ef8f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231ab6a6ca03498cb01481530e517c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Start typing some text...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b4ce9b3de743138864f1502a44b63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import termcolor\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def display_spellchecked(text):\n",
    "    mispellings = spellcheck(text)\n",
    "\n",
    "    mispelled_indices = []\n",
    "    \n",
    "    for word, start_index in mispellings:\n",
    "        mispelled_indices += range(start_index, start_index + len(word))\n",
    "        \n",
    "    for i in range(len(text)):\n",
    "        if i in mispelled_indices:\n",
    "            termcolor.cprint(text[i], \"red\", end=\"\", attrs=[\"underline\"])\n",
    "        else:\n",
    "            print(text[i], end=\"\")\n",
    "    \n",
    "    return mispellings\n",
    "\n",
    "\n",
    "# Prompts the user for input and spellchecks it\n",
    "def spellchecker():\n",
    "    text = widgets.Text(value='',\n",
    "                        placeholder='Start typing some text...',\n",
    "                        disabled=False)\n",
    "    out = widgets.Output()\n",
    "    display(text)\n",
    "    display(out)\n",
    "    \n",
    "    def on_change(change):\n",
    "        text = change['new']\n",
    "        with out:\n",
    "            clear_output()\n",
    "            display_spellchecked(text)\n",
    "\n",
    "    text.observe(on_change, names=[\"value\"])\n",
    "    \n",
    "spellchecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c901a143-3dc7-497b-b5a0-e025ae187ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio \n",
    "\n",
    "demo = gradio.Interface(fn=spellcheck, inputs=\"text\", outputs=\"text\", live=True)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9271857-5550-4e22-be9a-5bcaacc1fdc4",
   "metadata": {},
   "source": [
    "## Allowing for new words\n",
    "Let's see how this behaves against a real, unseen text from our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b09ce01a-d9ea-4033-bbda-f1acc5179f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in pwes in tinyol pwes loke nmoo oj anm \u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mn\u001b[0m la jaa.\n",
      "I kwando oj \u001b[4m\u001b[31mb\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mk\u001b[0m ri' \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m jb'anik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\n",
      "i \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m qlen qe\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mz\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\n",
      "i ri' \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mq\u001b[0m chuch kaa'.\n",
      "xaq jun kitz re qadesayun\n",
      "i \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mk\u001b[0m,\n",
      "q'asaj jun ka' chirij chik\n",
      "i despwes \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mb\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m li,\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31ml\u001b[0m chik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mr\u001b[0m chik\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mr\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m jwich\n",
      "i ri' tqakoj \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31ma\u001b[0m.\n",
      "Ya \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31ma\u001b[0m li,\n",
      "bay despwes tb'it wunaq li\n",
      "tijtij \u001b[4m\u001b[31md\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31my\u001b[0m\u001b[4m\u001b[31mu\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\n",
      "tijmaj jwa li tib'e li chaak\n",
      "i despwes oj kan chik oj chik\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mz\u001b[0m\u001b[4m\u001b[31mu\u001b[0m\u001b[4m\u001b[31mq\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m,\n",
      "wi' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m tqaye' chik \u001b[4m\u001b[31md\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31my\u001b[0m\u001b[4m\u001b[31mu\u001b[0m\u001b[4m\u001b[31mn\u001b[0m rechaq\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mn\u001b[0m,\n",
      "bay tijmaj li \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31ma\u001b[0m chik re qadesayun li\n",
      "despwes \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m chik jb'anik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m chik juntir chik,\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mt\u001b[0m,\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m qlen qe,\n",
      "ch'ajmaj qelen qe oj \u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mk\u001b[0m...\n",
      "tk'is li qupiis li\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m rij \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m chik.\n",
      "Qane' kib' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m,\n",
      "b'antaj \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\n",
      "i \u001b[4m\u001b[31md\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m wi' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mp\u001b[0m tqab'an,\n",
      "tons tqamech' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mm\u001b[0m ojok \u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\n",
      "ya \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m ra \u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m qe\n",
      "ojok \u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mp\u001b[0m.\n",
      "\u001b[4m\u001b[31mT\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m, \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\n",
      "tqab'an de seys kwart\n",
      "o dyes kwart \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mr\u001b[0m\u001b[4m\u001b[31mq\u001b[0m...\n",
      "tqak'am chik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mm\u001b[0m chik,\n",
      "ojok \u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m jun \u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mo\u001b[0m"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\n",
    "\n",
    "with open(\"corpus-usp/68.txt\", 'r') as file:\n",
    "    test_text = file.read()\n",
    "\n",
    "_ = display_spellchecked(test_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f756499-d4a5-4c7a-aa8e-39da4c64c59c",
   "metadata": {},
   "source": [
    "There's a ton of false spelling errors detected! Because our system was built using only a small corpus, it will not contain every valid word in the language. Common word processing tools fix this problem by easily allowing the user to add a word to the dictionary, so let's modify our tool to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6ab8676-d3b5-47cc-9a8d-ad16ad7bfa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523e93bbdcf7416388989e53594d3f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Start typing some text...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d3c0acbc8144538f885842550ec334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_to_lexicon(word):\n",
    "    if word in lexicon:\n",
    "        lexicon[word] += 1\n",
    "    else:\n",
    "        lexicon[word] = 1\n",
    "\n",
    "# A better spellchecker, that lets you handle mispellings\n",
    "def spellchecker2():\n",
    "    text = widgets.Text(value='',\n",
    "                        placeholder='Start typing some text...',\n",
    "                        disabled=False)\n",
    "    out = widgets.Output()\n",
    "    display(text)\n",
    "    display(out)\n",
    "    \n",
    "    def on_change(change):\n",
    "        text = change['new']\n",
    "        with out:\n",
    "            clear_output()\n",
    "            mispellings = display_spellchecked(text)\n",
    "            print()\n",
    "            \n",
    "            for i, (word, start) in enumerate(mispellings):\n",
    "                print(\"\\nMispelled: \" + termcolor.colored(word, 'red'))\n",
    "                # print(\"(a)dd to dictionary, (i)gnore, add a(l)l to dictionary\")\n",
    "                add_button = widgets.Button(description=\"Add to dictionary\")\n",
    "                display(add_button)\n",
    "                \n",
    "                def add_button_clicked(b):\n",
    "                    add_to_lexicon(word)\n",
    "                    on_change(change)\n",
    "                add_button.on_click(add_button_clicked)\n",
    "\n",
    "\n",
    "    text.observe(on_change, names=[\"value\"])\n",
    "        \n",
    "spellchecker2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82380b8a-c3f4-4cdf-9cc7-46f3cd22268e",
   "metadata": {},
   "source": [
    "Now, we can easily add any words that are correctly spelled to our dictionary, and they will not be marked as errors in the future!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068ac35-b4bc-49a1-822c-e51ef2cc8ee0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Spell Correction\n",
    "Lastly, it would be nice to update our spellchecker so it gives suggestions for correct spelling when there was an error. To do this, we need to determine what word in our lexicon is closest to what was typed. We will use **edit distance**, a measure of how many edits (additions, deletions, changes) it takes to get from one string to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7f39974-5d96-4cd9-991a-5c5885ba222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tzijj', 'tziij', 'tzij']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def spelling_suggestions(word, n):\n",
    "    # 1. Calculate the edit distance between the word and every word in the lexicon\n",
    "    candidate_spellings = []\n",
    "    for item in lexicon.items():\n",
    "        edit_distance = nltk.edit_distance(item[0], word)\n",
    "        candidate_spellings.append((item[0], item[1], edit_distance))\n",
    "    \n",
    "    # 2. Find the top n closest words, sorted first by edit distance x[2] and then by word frequency x[1]\n",
    "    sorted_candidates = sorted(candidate_spellings, key=lambda x: (x[2], -x[1]))\n",
    "    top_n_candidates = sorted_candidates[:n]\n",
    "    top_n_words_only = [candidate[0] for candidate in top_n_candidates]\n",
    "    return top_n_words_only\n",
    "\n",
    "spelling_suggestions(\"tzijj\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc13b84e-326d-42e0-8062-d328c940da89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28750aa76f94b82866d0e502d773d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Start typing some text...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f921c1fc434563ae571f06d022578c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def spellchecker3():\n",
    "    text = widgets.Text(value='',\n",
    "                        placeholder='Start typing some text...',\n",
    "                        disabled=False)\n",
    "    out = widgets.Output()\n",
    "    display(text)\n",
    "    display(out)\n",
    "    \n",
    "    def on_change(change):\n",
    "        text = change['new']\n",
    "        with out:\n",
    "            clear_output()\n",
    "            mispellings = display_spellchecked(text)\n",
    "            print()\n",
    "            \n",
    "            for i, (word, start) in enumerate(mispellings):\n",
    "                print(\"\\nMispelled: \" + termcolor.colored(word, 'red'))\n",
    "                # print(\"(a)dd to dictionary, (i)gnore, add a(l)l to dictionary\")\n",
    "                add_button = widgets.Button(description=\"Add to dictionary\")\n",
    "                display(add_button)\n",
    "                \n",
    "                def add_button_clicked(b):\n",
    "                    add_to_lexicon(word)\n",
    "                    on_change(change)\n",
    "                add_button.on_click(add_button_clicked)\n",
    "                \n",
    "                suggestions = spelling_suggestions(word, 3)\n",
    "                print(f\"Suggestions: {suggestions[0]}, {suggestions[1]}, {suggestions[2]}\")\n",
    "\n",
    "\n",
    "    text.observe(on_change, names=[\"value\"])\n",
    "\n",
    "spellchecker3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624dd3af-c5fd-40ae-839d-d61c282a06fc",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this tutorial, we built a spellchecker tool for a low-resource language. This included:\n",
    "- Building a lexicon from source texts\n",
    "- Detecting mispelled words\n",
    "- Predicting the correct spelling using similarity metrics\n",
    "\n",
    "To see the spellchecker as a standalone app, go to **2a. Spellchecker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c320149-b3c3-499d-8b11-e64112d0cbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
