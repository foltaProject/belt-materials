{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026241db-a85c-4189-bf1e-20f76f3f3764",
   "metadata": {},
   "source": [
    "# Spellchecker\n",
    "\n",
    "One simple application we can use our corpus for is creating a basic spellchecker, like you might use in Microsoft Word.\n",
    "\n",
    "There are two approaches to creating a spellchecker system. \n",
    "1. Store a huge list of words in the language, and check that every typed word is also a word in that list.\n",
    "2. Store just roots, and use morphological information to determine if a typed word is a valid form of the root.\n",
    "\n",
    "While approach 2 certainly seems more ideal, it will take a lot more work to implement effectively. In fact, modern tools like Word tend to use approach 1, so we'll do that.\n",
    "\n",
    "## Data Preparation\n",
    "### Load the corpus\n",
    "First, we'd like to compile a list of all the words we have in our corpus. To do this, we'll read in each file and concatenate them into one giant string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88373e3e-3551-442a-81e3-89c42d22a80d",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byeen pwees e... chwaaj tanyool júnkitz,\n",
      "neen jb'aniik xan k'ex loq'laj uleew chi qawch.\n",
      "Pero ajki' maas ójor\n",
      "raaj lajori juun kawunaq junaab' o se'a kwarenta años.\n",
      "E... jb'aniik k'ex loq'laj muund,\n",
      "xan porke nen b'i ri re e..., e.... ójor xqil na,\n",
      "ki ta' tzaqsáj kaxlaan mees,\n",
      "ta' tib'ansáj juun seb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# If you're using your own corpus, change this to the correct directory\n",
    "corpus_directory = \"../corpora/usp\"\n",
    "\n",
    "# First, let's combine all of our corpus entries into a single, huge string.\n",
    "corpus = \"\"\n",
    "\n",
    "# Loop over each file in the corpus so we can read it in\n",
    "for file_name in os.listdir(corpus_directory):\n",
    "    \n",
    "    # We will save one corpus entry, 68, for testing\n",
    "    if file_name == \"68.txt\" or \".txt\" not in file_name:\n",
    "        continue\n",
    "        \n",
    "    # Read the current file as a string\n",
    "    file_path = os.path.join(corpus_directory, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_contents = file.read()\n",
    "        corpus += (file_contents + \"\\n\")\n",
    "        \n",
    "print(corpus[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80b9a7b-b9c5-4c9f-b2f6-dc0db4a7000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255361"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many characters are in our corpus?\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2503ef9-3038-4c67-b713-2de6032d5f38",
   "metadata": {},
   "source": [
    "### Normalize characters\n",
    "In Uspanteko, accent marks are used to indicate tone in the transcriptions. However, a speaker might not write them, so we will strip them.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    If your language uses accent marks in the writing system, feel free to skip this cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d8f4edb-3350-423f-bd22-7569e94ff2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ojor taq tziij kita' jaa,\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def strip_accents(text: str) -> str:\n",
    "    # For each character, \"normalize\" it to a unicode character without an accent mark\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "corpus = strip_accents(corpus)\n",
    "strip_accents(\"ójor taq tziij kita' jaa,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4556503f-72df-49c2-ac3a-6e1621944b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's also make everything lowercase\n",
    "corpus = corpus.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dd7d96-a256-4b7a-98d4-32cae7a7e353",
   "metadata": {},
   "source": [
    "## Create a word list\n",
    "Now, let's create a list of every word that occurs in our corpus. We will ignore punctuation marks and assume that a word is surrounded by spaces or punctuation. Additionally, we'll keep a count of the frequency of each word for use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fc4657-827d-412d-90a9-c637797a6e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'x', '≈', '¡', 'm', \"'\", 'n', 's', 'r', 'g', 'h', '(', 'c', 'j', 'z', '[', '/', 'l', '.', ']', 'u', 'y', 'b', '\\n', 'ß', 'k', 'a', 'q', 'f', ' ', 'p', 'e', ',', '!', 'i', 't', 'd', '?', ')', 'v', '¿', ':', 'w'}\n"
     ]
    }
   ],
   "source": [
    "# Let's see what characters appear in our corpus\n",
    "# Using a set creates a list of the unique characters from our string\n",
    "print(set(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9cda2-0ca6-4e61-afc1-a633c219a8a8",
   "metadata": {},
   "source": [
    "### Tokenize words using a regular expression\n",
    "> **Tokenization** refers to the process of breaking a string up into tokens. Tokens might be words, characters, or morphemes. In this case, we are tokenizing into words.\n",
    "\n",
    "We will use a [regular expression](./skills/regex.ipynb) that looks for clumps of letters and apostrophes. When we run the regex over our text, each clump it finds is a separate word.\n",
    "\n",
    "For instance, in the following string:\n",
    "\n",
    "```ójor taq tziij kita' jaa```\n",
    "\n",
    "The regex will produce:\n",
    "\n",
    "```[\"ojor\", \"taq\", \"tziij\", \"kita'\", \"jaa\"]```\n",
    "\n",
    "In Uspanteko, words are always divided by punctuation or whitespace. Therefore, we can assume each clump that contains only letters must be a word.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Your language might need a custom regex for detecting words. Please refer to the lesson on regular expressions for information, and you can use a regex testing tool such as <a href='https://regex101.com'>regex101</a> to make sure your regex works the way you expect.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1c7386d-a990-4494-9172-0a3e1aa60e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Byeen',\n",
       " 'pwees',\n",
       " 'e',\n",
       " 'chwaaj',\n",
       " 'tanyool',\n",
       " 'júnkitz',\n",
       " 'neen',\n",
       " \"jb'aniik\",\n",
       " 'xan',\n",
       " \"k'ex\",\n",
       " \"loq'laj\",\n",
       " 'uleew',\n",
       " 'chi',\n",
       " 'qawch',\n",
       " 'Pero']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Find just words\n",
    "# If your language uses some other character within words (like hyphens) you may need to update this regex appropriately\n",
    "word_regex = r\"[\\w|\\']+\"\n",
    "\n",
    "# Takes a string and breaks it into a list of words\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return re.findall(word_regex, text)\n",
    "\n",
    "words = tokenize(corpus)\n",
    "words[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb9a28-1c26-446c-b262-3f4b2952b0d3",
   "metadata": {},
   "source": [
    "### Create a lexicon\n",
    "\n",
    "> A **lexicon** refers to the entire vocabulary of words used in the corpus\n",
    "\n",
    "To create a lexicon, we will iterate over every word in the entire corpus. We use a [dictionary](./skills/sets.ipynb) to keep track of each word and its frequency. The *keys* of the dictionary are each word in the vocabulary, and the *values* are the number of times the word appears in the corpus. For instance, we might see the following entry in an English corpus:\n",
    "\n",
    "```{ 'the': 10,000 } ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86257940-26f6-43bd-bcf3-7d028b4ecc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'lexicon' (dict)\n",
      "Created lexicon with 6771 unique words\n"
     ]
    }
   ],
   "source": [
    "lexicon = dict()\n",
    "\n",
    "for word in words:\n",
    "    # Check if the word is in the lexicon already (we've seen it before)\n",
    "    # If so, add one to the count\n",
    "    if word in lexicon:\n",
    "        lexicon[word] += 1\n",
    "    else:\n",
    "        lexicon[word] = 1\n",
    "\n",
    "# Store the lexicon to permanent storage so we can retrieve it later if needed\n",
    "%store lexicon\n",
    "\n",
    "print(f\"Created lexicon with {len(lexicon)} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7984ef5-c1c1-482a-a7dd-7d90a69f49a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taq', 1337),\n",
       " ('re', 1267),\n",
       " ('li', 1203),\n",
       " (\"cha'\", 1010),\n",
       " ('i', 988),\n",
       " ('man', 809),\n",
       " (\"ta'\", 782),\n",
       " ('jun', 740),\n",
       " (\"wi'\", 581),\n",
       " ('ra', 575),\n",
       " ('ri', 419),\n",
       " (\"ri'\", 386),\n",
       " ('anm', 361),\n",
       " ('chaq', 360),\n",
       " ('chi', 350),\n",
       " ('ke', 328),\n",
       " ('ya', 322),\n",
       " ('chik', 316),\n",
       " ('iin', 283),\n",
       " ('qe', 265)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what the twenty most common words are\n",
    "# This line sorts the lexicon by frequency and picks the first 20 items\n",
    "sorted(lexicon.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc0639-73ed-4bde-9ff6-16c7b875e69e",
   "metadata": {},
   "source": [
    "## Building a spellchecker\n",
    "At this point, we have a lexicon with all of our words and their frequencies. Now we're ready to build our spellchecker program. \n",
    "\n",
    "### Find mispelled words\n",
    "Let's create a function that will take a sentence and find any mispelled words. To do this, we will do the following:\n",
    "1. Preprocess the sentence to remove accents and make everything lowercase, tokenize\n",
    "2. For each word, check if it occurs in our lexicon. If not, it's a spelling error.\n",
    "3. Use regex to find where the word occurs in the original text.\n",
    "4. Return the mispelled words and their positions.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Right now, any time we see a word that isn't in our lexicon, we report it as a spelling error (even if its a new, correctly spelled word). We'll improve this later.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee73016-29bc-452c-a26a-de18713fff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kwand xink'uli'k', re ójr taq tzijj in ák'el na.\n",
      "tzijj at 30\n"
     ]
    }
   ],
   "source": [
    "def spellcheck(s: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"Finds mispelled words in a string.\n",
    "    :return: A list of tuples. Each tuple is (word, index) where `word` is the mispelled word and `index` is the index where it occurs.\n",
    "    \"\"\"\n",
    "    # 1. Preprocess and tokenize\n",
    "    s = strip_accents(s)\n",
    "    s = s.lower()\n",
    "    \n",
    "    # We can use a set, so we don't have to check duplicate words\n",
    "    input_words = set(tokenize(s))\n",
    "    \n",
    "    \n",
    "    # 2. Check each word in the input\n",
    "    mispelled = [] \n",
    "    for word in input_words:\n",
    "        # Does the word occur in our lexicon?\n",
    "        if not word in lexicon.keys():\n",
    "            # 3. Find the indices of the word in the original text\n",
    "            # This regex searches for the given word, surrounded by whitespace or punctuation\n",
    "            word_regex = f\"(^|\\W)({word})($|\\W)\"\n",
    "            \n",
    "            # There might be multiple matches if we mispelled a word multiple times\n",
    "            for match in re.finditer(word_regex, s):\n",
    "                mispelled.append((word, match.start(2)))\n",
    "    \n",
    "    # 4. Return the mispelled words, sorted by their position\n",
    "    return sorted(mispelled, key = lambda x: x[1])\n",
    "\n",
    "\n",
    "# This word has one mispelling ('tzijj')\n",
    "# If using your own langauge, replace with some test sentence\n",
    "test_sentence = \"Kwand xink'uli'k', re ójr taq tzijj in ák'el na.\"\n",
    "print(test_sentence)\n",
    "\n",
    "mispellings = spellcheck(test_sentence)\n",
    "for mispelled_word, location in mispellings:\n",
    "    print(f\"{mispelled_word} at {location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79955b23-48a1-43dd-8f1a-3139aa0f65b4",
   "metadata": {},
   "source": [
    "### Improving the user experience\n",
    "\n",
    "Our function `spellcheck` works to detect spelling errors. But this isn't a great tool for a user to use, so let's make it nicer to input text and see output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7717609-460d-446f-9f53-9dcd84ef8f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'termcolor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtermcolor\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwidgets\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'termcolor'"
     ]
    }
   ],
   "source": [
    "import termcolor\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def display_spellchecked(text):\n",
    "    mispellings = spellcheck(text)\n",
    "\n",
    "    mispelled_indices = []\n",
    "    \n",
    "    for word, start_index in mispellings:\n",
    "        mispelled_indices += range(start_index, start_index + len(word))\n",
    "        \n",
    "    for i in range(len(text)):\n",
    "        if i in mispelled_indices:\n",
    "            termcolor.cprint(text[i], \"red\", end=\"\", attrs=[\"underline\"])\n",
    "        else:\n",
    "            print(text[i], end=\"\")\n",
    "    \n",
    "    return mispellings\n",
    "\n",
    "\n",
    "# Prompts the user for input and spellchecks it\n",
    "def spellchecker():\n",
    "    text = widgets.Text(value='',\n",
    "                        placeholder='Start typing some text...',\n",
    "                        disabled=False)\n",
    "    out = widgets.Output()\n",
    "    display(text)\n",
    "    display(out)\n",
    "    \n",
    "    def on_change(change):\n",
    "        text = change['new']\n",
    "        with out:\n",
    "            clear_output()\n",
    "            display_spellchecked(text)\n",
    "\n",
    "    text.observe(on_change, names=[\"value\"])\n",
    "    \n",
    "spellchecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c901a143-3dc7-497b-b5a0-e025ae187ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio \n",
    "\n",
    "demo = gradio.Interface(fn=spellcheck, inputs=\"text\", outputs=\"text\", live=True)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9271857-5550-4e22-be9a-5bcaacc1fdc4",
   "metadata": {},
   "source": [
    "## Allowing for new words\n",
    "Let's see how this behaves against a real, unseen text from our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b09ce01a-d9ea-4033-bbda-f1acc5179f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in pwes in tinyol pwes loke nmoo oj anm \u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mn\u001b[0m la jaa.\n",
      "I kwando oj \u001b[4m\u001b[31mb\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mk\u001b[0m ri' \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m jb'anik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\n",
      "i \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m qlen qe\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mz\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\n",
      "i ri' \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mq\u001b[0m chuch kaa'.\n",
      "xaq jun kitz re qadesayun\n",
      "i \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mk\u001b[0m,\n",
      "q'asaj jun ka' chirij chik\n",
      "i despwes \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mb\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m li,\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31ml\u001b[0m chik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mr\u001b[0m chik\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mr\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m jwich\n",
      "i ri' tqakoj \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31ma\u001b[0m.\n",
      "Ya \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31ma\u001b[0m li,\n",
      "bay despwes tb'it wunaq li\n",
      "tijtij \u001b[4m\u001b[31md\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31my\u001b[0m\u001b[4m\u001b[31mu\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\n",
      "tijmaj jwa li tib'e li chaak\n",
      "i despwes oj kan chik oj chik\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mz\u001b[0m\u001b[4m\u001b[31mu\u001b[0m\u001b[4m\u001b[31mq\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m,\n",
      "wi' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m tqaye' chik \u001b[4m\u001b[31md\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31my\u001b[0m\u001b[4m\u001b[31mu\u001b[0m\u001b[4m\u001b[31mn\u001b[0m rechaq\n",
      "\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mn\u001b[0m,\n",
      "bay tijmaj li \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31ma\u001b[0m chik re qadesayun li\n",
      "despwes \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m chik jb'anik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m chik juntir chik,\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mt\u001b[0m,\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m qlen qe,\n",
      "ch'ajmaj qelen qe oj \u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mk\u001b[0m...\n",
      "tk'is li qupiis li\n",
      "\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m rij \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m chik.\n",
      "Qane' kib' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m,\n",
      "b'antaj \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\n",
      "i \u001b[4m\u001b[31md\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31ms\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mw\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31ms\u001b[0m wi' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mp\u001b[0m tqab'an,\n",
      "tons tqamech' \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mm\u001b[0m ojok \u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\n",
      "ya \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m ra \u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mj\u001b[0m qe\n",
      "ojok \u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mo\u001b[0m\u001b[4m\u001b[31mp\u001b[0m.\n",
      "\u001b[4m\u001b[31mT\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m, \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mx\u001b[0m\u001b[4m\u001b[31me\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mj\u001b[0m\n",
      "tqab'an de seys kwart\n",
      "o dyes kwart \u001b[4m\u001b[31mt\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mr\u001b[0m\u001b[4m\u001b[31mq\u001b[0m...\n",
      "tqak'am chik \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mp\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31ml\u001b[0m\u001b[4m\u001b[31mm\u001b[0m chik,\n",
      "ojok \u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mj\u001b[0m \u001b[4m\u001b[31mq\u001b[0m\u001b[4m\u001b[31m'\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mc\u001b[0m\u001b[4m\u001b[31mh\u001b[0m\u001b[4m\u001b[31mi\u001b[0m\u001b[4m\u001b[31mk\u001b[0m jun \u001b[4m\u001b[31mm\u001b[0m\u001b[4m\u001b[31ma\u001b[0m\u001b[4m\u001b[31mn\u001b[0m\u001b[4m\u001b[31mo\u001b[0m"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\n",
    "\n",
    "with open(\"corpus-usp/68.txt\", 'r') as file:\n",
    "    test_text = file.read()\n",
    "\n",
    "_ = display_spellchecked(test_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f756499-d4a5-4c7a-aa8e-39da4c64c59c",
   "metadata": {},
   "source": [
    "There's a ton of false spelling errors detected! Because our system was built using only a small corpus, it will not contain every valid word in the language. Common word processing tools fix this problem by easily allowing the user to add a word to the dictionary, so let's modify our tool to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6ab8676-d3b5-47cc-9a8d-ad16ad7bfa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523e93bbdcf7416388989e53594d3f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Start typing some text...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d3c0acbc8144538f885842550ec334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_to_lexicon(word):\n",
    "    if word in lexicon:\n",
    "        lexicon[word] += 1\n",
    "    else:\n",
    "        lexicon[word] = 1\n",
    "\n",
    "# A better spellchecker, that lets you handle mispellings\n",
    "def spellchecker2():\n",
    "    text = widgets.Text(value='',\n",
    "                        placeholder='Start typing some text...',\n",
    "                        disabled=False)\n",
    "    out = widgets.Output()\n",
    "    display(text)\n",
    "    display(out)\n",
    "    \n",
    "    def on_change(change):\n",
    "        text = change['new']\n",
    "        with out:\n",
    "            clear_output()\n",
    "            mispellings = display_spellchecked(text)\n",
    "            print()\n",
    "            \n",
    "            for i, (word, start) in enumerate(mispellings):\n",
    "                print(\"\\nMispelled: \" + termcolor.colored(word, 'red'))\n",
    "                # print(\"(a)dd to dictionary, (i)gnore, add a(l)l to dictionary\")\n",
    "                add_button = widgets.Button(description=\"Add to dictionary\")\n",
    "                display(add_button)\n",
    "                \n",
    "                def add_button_clicked(b):\n",
    "                    add_to_lexicon(word)\n",
    "                    on_change(change)\n",
    "                add_button.on_click(add_button_clicked)\n",
    "\n",
    "\n",
    "    text.observe(on_change, names=[\"value\"])\n",
    "        \n",
    "spellchecker2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82380b8a-c3f4-4cdf-9cc7-46f3cd22268e",
   "metadata": {},
   "source": [
    "Now, we can easily add any words that are correctly spelled to our dictionary, and they will not be marked as errors in the future!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068ac35-b4bc-49a1-822c-e51ef2cc8ee0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Spell Correction\n",
    "Lastly, it would be nice to update our spellchecker so it gives suggestions for correct spelling when there was an error. To do this, we need to determine what word in our lexicon is closest to what was typed. We will use **edit distance**, a measure of how many edits (additions, deletions, changes) it takes to get from one string to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7f39974-5d96-4cd9-991a-5c5885ba222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tzijj', 'tziij', 'tzij']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def spelling_suggestions(word, n):\n",
    "    # 1. Calculate the edit distance between the word and every word in the lexicon\n",
    "    candidate_spellings = []\n",
    "    for item in lexicon.items():\n",
    "        edit_distance = nltk.edit_distance(item[0], word)\n",
    "        candidate_spellings.append((item[0], item[1], edit_distance))\n",
    "    \n",
    "    # 2. Find the top n closest words, sorted first by edit distance x[2] and then by word frequency x[1]\n",
    "    sorted_candidates = sorted(candidate_spellings, key=lambda x: (x[2], -x[1]))\n",
    "    top_n_candidates = sorted_candidates[:n]\n",
    "    top_n_words_only = [candidate[0] for candidate in top_n_candidates]\n",
    "    return top_n_words_only\n",
    "\n",
    "spelling_suggestions(\"tzijj\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc13b84e-326d-42e0-8062-d328c940da89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28750aa76f94b82866d0e502d773d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Start typing some text...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f921c1fc434563ae571f06d022578c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def spellchecker3():\n",
    "    text = widgets.Text(value='',\n",
    "                        placeholder='Start typing some text...',\n",
    "                        disabled=False)\n",
    "    out = widgets.Output()\n",
    "    display(text)\n",
    "    display(out)\n",
    "    \n",
    "    def on_change(change):\n",
    "        text = change['new']\n",
    "        with out:\n",
    "            clear_output()\n",
    "            mispellings = display_spellchecked(text)\n",
    "            print()\n",
    "            \n",
    "            for i, (word, start) in enumerate(mispellings):\n",
    "                print(\"\\nMispelled: \" + termcolor.colored(word, 'red'))\n",
    "                # print(\"(a)dd to dictionary, (i)gnore, add a(l)l to dictionary\")\n",
    "                add_button = widgets.Button(description=\"Add to dictionary\")\n",
    "                display(add_button)\n",
    "                \n",
    "                def add_button_clicked(b):\n",
    "                    add_to_lexicon(word)\n",
    "                    on_change(change)\n",
    "                add_button.on_click(add_button_clicked)\n",
    "                \n",
    "                suggestions = spelling_suggestions(word, 3)\n",
    "                print(f\"Suggestions: {suggestions[0]}, {suggestions[1]}, {suggestions[2]}\")\n",
    "\n",
    "\n",
    "    text.observe(on_change, names=[\"value\"])\n",
    "\n",
    "spellchecker3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624dd3af-c5fd-40ae-839d-d61c282a06fc",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this tutorial, we built a spellchecker tool for a low-resource language. This included:\n",
    "- Building a lexicon from source texts\n",
    "- Detecting mispelled words\n",
    "- Predicting the correct spelling using similarity metrics\n",
    "\n",
    "To see the spellchecker as a standalone app, go to **2a. Spellchecker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c320149-b3c3-499d-8b11-e64112d0cbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
